{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bd7d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ningn\\anaconda3\\envs\\translate\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 / 113成功追加 1 个标签到 C:\\Users\\ningn\\Desktop\\やる夫たちが黒い玉の部屋に行くようです\\「黑玉」二部第33话.html 末尾\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from config import Config\n",
    "mode = 'gemini'\n",
    "# 配置Gemini API\n",
    "genai.configure(api_key=Config.GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "#model = genai.GenerativeModel('gemini-2.5-flash-lite-preview-06-17')\n",
    "# 初始化OpenAI API \n",
    "client = OpenAI(api_key=\"key\", base_url=\"https://api.deepseek.com\")\n",
    "# 配置参数\n",
    "CONFIG = {\n",
    "    \"model\": \"deepseek-chat\",\n",
    "    \"translate_prompt\": \"\"\"请严格遵循以下要求处理文本：\n",
    "1. 仅翻译日文句子和短语为简体中文\n",
    "2. 保留所有ASCII艺术图形字符\n",
    "3. 保持HTML标签（<...>）完整不变\n",
    "4. 保留数字、专有名词和拟声词\n",
    "5. 若无非日文内容，返回原始文本\n",
    "输出格式要求：仅返回处理后的文本，不要添加任何说明\"\"\",\n",
    "    \"temperature\": 1,\n",
    "    \"batch_size\": 10,\n",
    "    \"max_workers\": 5,\n",
    "    \"max_tokens\": 8190\n",
    "}\n",
    "# API调用间隔（秒）\n",
    "API_COOLDOWN = 5\n",
    "\n",
    "def translate_japanese_to_chinese(text):\n",
    "    \"\"\"同步翻译函数\"\"\"\n",
    "\n",
    "    if mode == 'gemini':\n",
    "        # API调用频率控制\n",
    "        time.sleep(API_COOLDOWN)  \n",
    "        response = model.generate_content(f\"识别出以下文本中所有的日文句子或短语并翻译成简体中文，仅输出翻译部分的文本内容。不要产出任何其余与翻译无关的回复文本：{text}\")\n",
    "        if not response.candidates or not response.parts:\n",
    "            translated = \"\"\n",
    "        else:\n",
    "            translated = response.text\n",
    "    elif mode == 'chatgpt':\n",
    "        response = client.chat.completions.create(\n",
    "                    model=CONFIG[\"model\"],\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": CONFIG[\"translate_prompt\"]},\n",
    "                        {\"role\": \"user\", \"content\": text}\n",
    "                    ],\n",
    "                    temperature=CONFIG[\"temperature\"],\n",
    "                    max_tokens=CONFIG[\"max_tokens\"]\n",
    "                )\n",
    "        translated = response.choices[0].message.content\n",
    "    else: print(\"Unknown mode: \",mode)\n",
    "    #cut = translated.replace(' ', '<br/>')\n",
    "    return translated\n",
    "def extract_dt_content(input_files):\n",
    "    \"\"\"从输入文件中提取所有<dt>标签内容\"\"\"\n",
    "    all_dt = []\n",
    "    if not os.path.exists(input_files):\n",
    "        print(f\"警告：文件 {input_files} 不存在，已跳过\")\n",
    "\n",
    "    with open(input_files, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "        for dt in soup.find_all('div', class_='content entry grid_content p_area'):\n",
    "            # 克隆标签避免跨文档污染\n",
    "            all_dt.append(dt)\n",
    "    return all_dt\n",
    "def split_posts(html_text):\n",
    "    # 定义匹配每楼开头的正则表达式模式\n",
    "    pattern = r'(\\d+\\s*：.*?.*?)'\n",
    "    #pattern = \"疫病 ◆fJrHveEGcs\"\n",
    "    # 使用正则表达式进行分割，保留分隔符\n",
    "    parts = re.split(pattern, html_text)\n",
    "    \n",
    "    # # 过滤空字符串并重新组合\n",
    "    # posts = []\n",
    "    # for i in range(1, len(parts), 2):\n",
    "    #     if i + 1 < len(parts):\n",
    "    #         post = parts[i] + parts[i + 1]\n",
    "    #         posts.append(post)\n",
    "    \n",
    "    return parts\n",
    "def string_to_tag(html_str):\n",
    "    \"\"\"将字符串转换为 bs4.element.Tag 对象\"\"\"\n",
    "    # 重新解析字符串（需要包裹在<html>标签中确保结构完整）\n",
    "    soup = BeautifulSoup(f\"<html>{html_str}</html>\", 'lxml')\n",
    "    # 提取<body>内的第一个子元素（即原始字符串对应的标签）\n",
    "    return soup.html.body.next_element\n",
    "def append_dt_to_file(output_file, dt_contents):\n",
    "    \"\"\"将<dt>内容追加到目标文件末尾\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        html_content = \"\"\"\n",
    "        <html><div style=\"display: none;\"><link rel=\"stylesheet\" type=\"text/css\" href=\"https://transtemple.github.io/aaFont/aaFont.css\"></div><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"><title>疫病.html</title></head><body class=\"AA_Text\"><div>\n",
    "        <div style=\"display: none;\">&nbsp;</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \"\"\"同步处理HTML内容\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # 创建容器标签\n",
    "        container = soup.new_tag('div', id='appended-dt-content')\n",
    "        container.append(soup.new_tag('hr'))  # 添加分割线\n",
    "        \n",
    "        # 插入所有DT内容\n",
    "        dl_tag = soup.new_tag('hr')\n",
    "        for dt in dt_contents:\n",
    "            dl_tag.append(dt)\n",
    "        container.append(dl_tag)\n",
    "        \n",
    "        # 定位到body末尾\n",
    "        if soup.body:\n",
    "            soup.body.append(container)\n",
    "        else:\n",
    "            # 如果原文件没有body则创建\n",
    "            body = soup.new_tag('body')\n",
    "            body.append(container)\n",
    "            soup.html.append(body)\n",
    "        \n",
    "        dls = soup.find('div', class_='fc2button-clap')\n",
    "        # 方式2：删除所有后续元素\n",
    "        for element in dls.find_all_next():\n",
    "            element.decompose()\n",
    "        dls.decompose()\n",
    "        \n",
    "        \n",
    "        target_cell = soup.find('h2', class_='entry_header')\n",
    "        if target_cell:\n",
    "            text = str(target_cell)\n",
    "            insert_pos = text.find('</h2>')\n",
    "            modified_html = \"\"\n",
    "            modified_html += text[:insert_pos]\n",
    "            modified_html += '<br/>'\n",
    "            modified_html += translate_japanese_to_chinese(text)\n",
    "            modified_html += text[insert_pos:]\n",
    "            tag_obj = string_to_tag(modified_html)\n",
    "            target_cell.replace_with(tag_obj)\n",
    "        li = soup.find('ul')\n",
    "        li.decompose()\n",
    "        # 重建文档结构\n",
    "        new_html = str(soup)\n",
    "        # 确保基本结构完整性\n",
    "        if '</html>' not in new_html:\n",
    "            new_html += '\\n</html>'\n",
    "\n",
    "        coll = soup.find('div', class_='entry_body')\n",
    "        text = str(coll)\n",
    "        posts = split_posts(text)\n",
    "        # print(posts)\n",
    "        # print(len(posts))\n",
    "        # 进行翻译\n",
    "        i=1\n",
    "        new_text = posts[0]\n",
    "        total = int(len(posts[1:])/2)\n",
    "        for j in range(total):\n",
    "            # 输出进度条 \n",
    "            sys.stdout.write(f\"\\r{i} / {total}\")\n",
    "            sys.stdout.flush()\n",
    "            i += 1\n",
    "            if posts[1:][j]:\n",
    "                new_text += posts[1:][2*j]\n",
    "                text = str(posts[1:][2*j+1])\n",
    "                modified_html = \"\"\n",
    "                cut_pos = text.find('<br/><br/><br/><br/>')\n",
    "                while cut_pos != -1:\n",
    "                    modified_html += text[:cut_pos]\n",
    "                    modified_html += '<br/><br/>'\n",
    "                    if text[:cut_pos]:\n",
    "                        #print(\"input: \",text[:cut_pos])\n",
    "                        check = translate_japanese_to_chinese(text[:cut_pos])\n",
    "                        #print(\"output: \",check)\n",
    "                        modified_html += check\n",
    "                    text = text[15+cut_pos:]\n",
    "                    cut_pos = text.find('<br/><br/><br/><br/>')\n",
    "                modified_html += text\n",
    "                check = translate_japanese_to_chinese(text)\n",
    "                #print(\"output: \",check)\n",
    "                modified_html += check\n",
    "                # if 2*j+1 == len(posts[1:])-1:\n",
    "                #     print(text)\n",
    "                #     print(\"output: \",check)\n",
    "                modified_html += '<br/><br/>'\n",
    "                new_text += modified_html\n",
    "        # 执行转换\n",
    "\n",
    "        tag_obj = string_to_tag(new_text)\n",
    "        coll.replace_with(tag_obj)\n",
    "        # 美化格式后写入\n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        f.write(str(soup))  # 使用HTML5格式\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置参数\n",
    "    input_files = r\"C:\\Users\\ningn\\Downloads\\やる夫たちがカタストロフィを生き延びるようです　Ep.33 「反逆する牙」 - だっておｗｗｗキャンセル.html\"\n",
    "    output_file = r\"C:\\Users\\ningn\\Desktop\\やる夫たちが黒い玉の部屋に行くようです\\「黑玉」二部第33话.html\"\n",
    "    \n",
    "    # 执行流程\n",
    "    dt_elements = extract_dt_content(input_files)\n",
    "    if dt_elements:\n",
    "        append_dt_to_file(output_file, dt_elements)\n",
    "        print(f\"成功追加 {len(dt_elements)} 个标签到 {output_file} 末尾\")\n",
    "    else:\n",
    "        print(\"未找到目标标签内容\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5d29f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'就算你不说，我也会那么做的。本来就是你们擅自跟来的而已嘛。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"言われなくともそうするさ 元よりおまえたちが「勝手に」ついてきただけだからな\"\n",
    "translate_japanese_to_chinese(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
