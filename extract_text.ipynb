{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e6bf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 / 116成功追加 1 个<dt>标签到 C:\\Users\\ningn\\Downloads\\test2.html 末尾\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from openai import OpenAI\n",
    "mode = 'chatgpt'\n",
    "# 配置Gemini API\n",
    "GENAI_API_KEY = \"AIzaSyD4QToVDHXIdzoaSjrhm_VVtuLxFf0gNaA\"  # 替换为你的实际API密钥\n",
    "genai.configure(api_key=GENAI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "# 初始化OpenAI API \n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# 配置参数\n",
    "CONFIG = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"translate_prompt\": \"\"\"请严格遵循以下要求处理文本：\n",
    "1. 仅翻译日文句子和短语为简体中文\n",
    "2. 保留所有ASCII艺术图形字符\n",
    "3. 保持HTML标签（<...>）完整不变\n",
    "4. 保留数字、专有名词和拟声词\n",
    "5. 若无非日文内容，返回原始文本\n",
    "输出格式要求：仅返回处理后的文本，不要添加任何说明\"\"\",\n",
    "    \"temperature\": 0.3,\n",
    "    \"batch_size\": 10,\n",
    "    \"max_workers\": 5,\n",
    "    \"max_tokens\": 10000\n",
    "}\n",
    "# API调用间隔（秒）\n",
    "API_COOLDOWN = 1  \n",
    "\n",
    "def translate_japanese_to_chinese(text):\n",
    "    \"\"\"同步翻译函数\"\"\"\n",
    "\n",
    "    if mode == 'gemini':\n",
    "        # API调用频率控制\n",
    "        time.sleep(API_COOLDOWN)  \n",
    "\n",
    "        response = model.generate_content(f\"识别以下文本中所有的日文句子或短语并翻译成简体中文，保留其他图形字符（ASCII Art）部分和非日文句子或短语部分不变，保留用<>表示的tag不变。保留数字、专有名词、和拟声词。如果没有日文语句，则输出原始的输入文本。不要产出任何其余回复：{text}\")\n",
    "        translated = response.text\n",
    "    elif mode == 'chatgpt':\n",
    "        response = client.chat.completions.create(\n",
    "                    model=CONFIG[\"model\"],\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": CONFIG[\"translate_prompt\"]},\n",
    "                        {\"role\": \"user\", \"content\": str(text)}\n",
    "                    ],\n",
    "                    temperature=CONFIG[\"temperature\"],\n",
    "                    max_tokens=CONFIG[\"max_tokens\"]\n",
    "                )\n",
    "        translated = response.choices[0].message.content\n",
    "    else: print(\"Unknown mode: \",mode)\n",
    "    return translated\n",
    "def extract_dt_content(input_files):\n",
    "    \"\"\"从输入文件中提取所有<dt>标签内容\"\"\"\n",
    "    all_dt = []\n",
    "    if not os.path.exists(input_files):\n",
    "        print(f\"警告：文件 {input_files} 不存在，已跳过\")\n",
    "\n",
    "    with open(input_files, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "        for dt in soup.find_all('div', class_='entry'):\n",
    "            # 克隆标签避免跨文档污染\n",
    "            all_dt.append(dt)\n",
    "    return all_dt\n",
    "\n",
    "def append_dt_to_file(output_file, dt_contents):\n",
    "    \"\"\"将<dt>内容追加到目标文件末尾\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        html_content = \"\"\"\n",
    "        <html><div style=\"display: none;\"><link rel=\"stylesheet\" type=\"text/css\" href=\"https://transtemple.github.io/aaFont/aaFont.css\"></div><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"><title>疫病.html</title></head><body class=\"AA_Text\"><div>\n",
    "        <div style=\"display: none;\">&nbsp;</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \"\"\"同步处理HTML内容\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # 创建容器标签\n",
    "        container = soup.new_tag('div', id='appended-dt-content')\n",
    "        container.append(soup.new_tag('hr'))  # 添加分割线\n",
    "        \n",
    "        # 插入所有DT内容\n",
    "        dl_tag = soup.new_tag('hr')\n",
    "        for dt in dt_contents:\n",
    "            dl_tag.append(dt)\n",
    "        container.append(dl_tag)\n",
    "        \n",
    "        # 定位到body末尾\n",
    "        if soup.body:\n",
    "            soup.body.append(container)\n",
    "        else:\n",
    "            # 如果原文件没有body则创建\n",
    "            body = soup.new_tag('body')\n",
    "            body.append(container)\n",
    "            soup.html.append(body)\n",
    "        for dt in soup.find_all('div', class_='navilink'):\n",
    "            dt.decompose()\n",
    "        # 查找所有dl标签\n",
    "        dls = soup.find_all('dl')\n",
    "        if not dls:\n",
    "            print(\"未找到任何<dl>标签\")\n",
    "            return\n",
    "\n",
    "        # 定位最后一个dl标签\n",
    "        last_dl = dls[-1]\n",
    "         # 方式1：删除后续所有兄弟元素\n",
    "        for sibling in last_dl.find_next_siblings():\n",
    "            sibling.decompose()\n",
    "        \n",
    "        dls = soup.find_all('div', class_='entry-info2')\n",
    "        last_dl = dls[-1]\n",
    "        # 方式2：删除所有后续元素\n",
    "        for element in last_dl.find_all_next():\n",
    "            element.decompose()\n",
    "        last_dl.decompose()\n",
    "        # 重建文档结构\n",
    "        new_html = str(soup)\n",
    "        \n",
    "        # 确保基本结构完整性\n",
    "        if '</html>' not in new_html:\n",
    "            new_html += '\\n</html>'\n",
    "        # 进行翻译\n",
    "        total = len(soup.find_all('dd'))\n",
    "        i=1\n",
    "        for element in soup.find_all('dd'):\n",
    "            # 输出进度条 \n",
    "            sys.stdout.write(f\"\\r{i} / {total}\")\n",
    "            sys.stdout.flush()\n",
    "            i += 1\n",
    "            # if element:\n",
    "\n",
    "            #     translated = translate_japanese_to_chinese(element)\n",
    "                \n",
    "            #     def string_to_tag(html_str):\n",
    "            #         \"\"\"将字符串转换为 bs4.element.Tag 对象\"\"\"\n",
    "            #         # 重新解析字符串（需要包裹在<html>标签中确保结构完整）\n",
    "            #         soup = BeautifulSoup(f\"<html>{html_str}</html>\", 'lxml')\n",
    "            #         # 提取<body>内的第一个子元素（即原始字符串对应的标签）\n",
    "            #         return soup.html.body.next_element\n",
    "\n",
    "            #     # 执行转换\n",
    "            #     tag_obj = string_to_tag(translated)\n",
    "            #     element.replace_with(tag_obj)\n",
    "        # 美化格式后写入\n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        f.write(str(soup))  # 使用HTML5格式\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置参数\n",
    "    input_files = r\"C:\\Users\\ningn\\Downloads\\【ほのぼの？】やる夫と町の怪奇譚【ホラー？】 第１話 『クチサケオンナ』(前編) その2 - 暇な時にやる夫まとめ.html\"\n",
    "    output_file = r\"C:\\Users\\ningn\\Downloads\\test2.html\"\n",
    "    \n",
    "    # 执行流程\n",
    "    dt_elements = extract_dt_content(input_files)\n",
    "    if dt_elements:\n",
    "        append_dt_to_file(output_file, dt_elements)\n",
    "        print(f\"成功追加 {len(dt_elements)} 个<dt>标签到 {output_file} 末尾\")\n",
    "    else:\n",
    "        print(\"未找到任何<dt>标签内容\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
